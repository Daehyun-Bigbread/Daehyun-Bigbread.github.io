---
layout: post
title: Deep learning Studying(28) - Activation Function Sigmoid
subtitle: Part.1 활성함수 Function Sigmoid
gh-repo: Daehyun-Bigbread/daehyun-bigbread.github.io
gh-badge: [star, fork, follow]
tags: [Deeplearning, pytorch]
comments: true
---

# Ch 07. 로지스틱 희귀(Logistic Regression)

## Part.1 Activation(활성함수) Function Sigmoid 

여기선 Sigmoid 함수와 TanH함수를 볼수 있다. 

* Sigmoid: 대표적인 Logistic 함수이며, 모든 실수 값을 0보다 크고 1보다 작은 미분 가능한 수로 변환하는 특징을 갖는다. 출력 범위는 0~1사이.

![20210720_134451 - 복사본](../../assets/img/20210720_134451 - 복사본.png)

* TanH: Sigmoid의 대체제로 사용될 수 있는 활성화 함수 입니다.  출력 범위는 -1 ~ 1 사이.

![20210720_134451](../../assets/img/20210720_134451.png)



* Sigmoid 함수와 TanH의 함수를 그래프화 한것이다.

![20210720_134525](../../assets/img/20210720_134525.png)

